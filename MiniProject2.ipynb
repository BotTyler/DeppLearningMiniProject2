{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 16:37:22.126755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-14 16:37:30.784226: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/tyler/miniconda3/envs/tf/lib/:/home/tyler/miniconda3/envs/tf/lib/\n",
      "2023-03-14 16:37:30.784315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/tyler/miniconda3/envs/tf/lib/:/home/tyler/miniconda3/envs/tf/lib/\n",
      "2023-03-14 16:37:30.784323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 16:37:33.412911: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-03-14 16:37:33.413211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: tyler-Lenovo-Y520-15IKBN\n",
      "2023-03-14 16:37:33.413244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: tyler-Lenovo-Y520-15IKBN\n",
      "2023-03-14 16:37:33.413539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.85.5\n",
      "2023-03-14 16:37:33.413649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.85.5\n",
      "2023-03-14 16:37:33.413675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.85.5\n",
      "2023-03-14 16:37:33.414588: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.activations import relu\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_squared_error\n",
    "#import tensorflow as tf\n",
    "\n",
    "model = keras.Sequential([\n",
    "    #data_augmentation,\n",
    "    keras.layers.Rescaling(1./255),\n",
    "    Conv2D(3, (5,5), strides=2, padding=\"same\", activation=relu, input_shape=(160,320,3)),\n",
    "    #MaxPooling2D(2),\n",
    "    Conv2D(24, (5, 5), strides=2, padding=\"same\", activation=relu),\n",
    "    #MaxPooling2D(2),\n",
    "    Conv2D(36, (5, 5), strides=2, padding=\"same\", activation=relu),\n",
    "    #MaxPooling2D(2),\n",
    "    Conv2D(48, (3, 3), strides=2, padding=\"same\", activation=relu),\n",
    "    #MaxPooling2D(2),\n",
    "    Conv2D(64, (3, 3), strides=2, padding=\"same\", activation=relu),\n",
    "    #MaxPooling2D(2),\n",
    "    #Conv2D(64, (3, 3), strides=2, padding=\"same\", activation=relu),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    #Dense(1164, activation=relu),\n",
    "    Dense(100, activation=relu),\n",
    "    Dense(50, activation=relu),\n",
    "    Dense(10, activation=relu),\n",
    "    Dense(1, activation=\"tanh\"),\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(loss=mean_squared_error, optimizer=Adam(), metrics=['mean_squared_error', 'mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv='/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/driving_log.csv'\n",
    "batchSize = 32\n",
    "train_ds=dataset(train_csv, batchsize=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 13:07:09.151227: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1228800000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Set the directory for your images\n",
    "image_dir = '/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/IMG/'\n",
    "size = 2000\n",
    "# Load the images into a list\n",
    "X = []\n",
    "for filename in os.listdir(image_dir)[:size]:\n",
    "    img_path = os.path.join(image_dir, filename)\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        img_path, target_size=(160,320)) #160, 320\n",
    "    X.append(tf.keras.preprocessing.image.img_to_array(img))\n",
    "\n",
    "# Convert the list of images to a NumPy array\n",
    "X = tf.convert_to_tensor(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/IMG/center_2023_03_14_12_44_13_550.jpg,/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/IMG/left_2023_03_14_12_44_13_550.jpg,/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/IMG/right_2023_03_14_12_44_13_550.jpg,0,0,0,2.104585'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset_y \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/driving_log.csv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                               delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, names\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mSteering\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m Y \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m      5\u001b[0m     train_dataset_y[\u001b[39m\"\u001b[39;49m\u001b[39mSteering\u001b[39;49m\u001b[39m\"\u001b[39;49m][:size]\u001b[39m.\u001b[39;49mvalues, dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/IMG/center_2023_03_14_12_44_13_550.jpg,/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/IMG/left_2023_03_14_12_44_13_550.jpg,/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/IMG/right_2023_03_14_12_44_13_550.jpg,0,0,0,2.104585'"
     ]
    }
   ],
   "source": [
    "train_dataset_y = pd.read_csv('/home/tyler/Desktop/testObjLab/autopilot_project/data_set/train_data/driving_log.csv',\n",
    "                              delimiter=\"\\t\", header=None, names=[\"Steering\"])\n",
    "\n",
    "Y = tf.convert_to_tensor(\n",
    "    train_dataset_y[\"Steering\"][:size].values, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from the images and labels\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "\n",
    "# Shuffle and batch the dataset\n",
    "#batch_size = 32\n",
    "#dataset = dataset.shuffle(buffer_size=len(X))\n",
    "#dataset = dataset.batch(batch_size)\n",
    "\n",
    "# Use 80% of data for training, 20% for validation\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "Y_train, Y_val = Y[:split_index], Y[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1600, 160, 300, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "181/181 [==============================] - 35s 191ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - mean_absolute_error: 0.0581\n",
      "Epoch 2/20\n",
      "181/181 [==============================] - 35s 191ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - mean_absolute_error: 0.0578\n",
      "Epoch 3/20\n",
      "181/181 [==============================] - 35s 194ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - mean_absolute_error: 0.0572\n",
      "Epoch 4/20\n",
      "181/181 [==============================] - 35s 192ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - mean_absolute_error: 0.0595\n",
      "Epoch 5/20\n",
      "181/181 [==============================] - 35s 191ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0579\n",
      "Epoch 6/20\n",
      "181/181 [==============================] - 35s 191ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - mean_absolute_error: 0.0579\n",
      "Epoch 7/20\n",
      "181/181 [==============================] - 35s 191ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0567\n",
      "Epoch 8/20\n",
      "181/181 [==============================] - 35s 194ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0580\n",
      "Epoch 9/20\n",
      "181/181 [==============================] - 35s 196ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0556\n",
      "Epoch 10/20\n",
      "181/181 [==============================] - 35s 194ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0554\n",
      "Epoch 11/20\n",
      "181/181 [==============================] - 35s 194ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0584\n",
      "Epoch 12/20\n",
      "181/181 [==============================] - 35s 193ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0573\n",
      "Epoch 13/20\n",
      "181/181 [==============================] - 36s 196ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0582\n",
      "Epoch 14/20\n",
      "181/181 [==============================] - 35s 195ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0564\n",
      "Epoch 15/20\n",
      "181/181 [==============================] - 34s 190ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0573\n",
      "Epoch 16/20\n",
      "181/181 [==============================] - 34s 190ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0581\n",
      "Epoch 17/20\n",
      "181/181 [==============================] - 34s 188ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0594\n",
      "Epoch 18/20\n",
      "181/181 [==============================] - 34s 189ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0574\n",
      "Epoch 19/20\n",
      "181/181 [==============================] - 35s 191ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0568\n",
      "Epoch 20/20\n",
      "181/181 [==============================] - 35s 194ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - mean_absolute_error: 0.0559\n"
     ]
    }
   ],
   "source": [
    "#callbacks = [\n",
    "#    keras.callbacks.ModelCheckpoint(\n",
    "#        filepath=\"myModel.h5\",\n",
    "#        save_best_only=True,\n",
    "#        monitor=\"val_loss\")\n",
    "#]\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"myModel.h5\",\n",
    "    )\n",
    "]\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 200, 200, 3)       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 200, 200, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 100, 100, 3)       228       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 24)        1824      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 25, 36)        21636     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 48)        15600     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 64)          27712     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               102500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 211,999\n",
      "Trainable params: 211,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m val_accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mval_mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"mean_squared_error\"]\n",
    "val_accuracy = history.history[\"val_mean_squared_error\"]\n",
    "loss = history.history[\"mean_absolute_error\"]\n",
    "val_loss = history.history[\"val_mean_absolute_error\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation\")\n",
    "plt.title(\"Training and validation MSE\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
